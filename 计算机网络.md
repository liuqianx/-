# 计算机网络

## 1. 四层架构

一次URL访问：首先通过查找本地或者外网DNS解析域名获得IP地址，然后生成一个HTTP请求；TCP分割HTTP报文，同时尝试建立与远程主机的TCP连接；为了建立TCP连接，需要通过IP协议在网络层中寻路；首先判断目的IP地址是否处于同一子网，如不在则将IP包发向default gateway，通过查询Router的routing table在网络层中寻路，最后找到目的主机所在局域网，查询Router上的ARP table是否有此IP地址的记录，否则通过广播找到目的地的MAC所在，建立点对点的连接。TCP连接建立完成后服务端返回一个HTTP报文，里面夹带了HTML/CSS/JS，服务器渲染生成我们看到的页面。

1. 数据链路层：单纯的电信号0和1没有任何意义，必须规定电信号多少位一组，每组什么意思；数据链路层定义了电信号的分组方式，定义了主机的MAC地址，把实现控制数据运输的协议的硬件和软件加到链路上。通过各种控制协议，将有差错的物理信道变为无差错的、能可靠传输数据帧的数据链路。
   - 点对点信道/PPP、广播信道
   - Ethernet协议、ARP协议（介于数据链路层和网络层之间）
   - 每个host/router都有一个ARP table，记录局域网里各主机/路由器的IP和MAC地址映射。
   - 中继系统：网桥（bridge）、交换机（switch）
   
2. 网络层：提供路由和寻址的功能，使两终端系统能够互连且决定最佳路径，并具有一定的拥塞控制和流量控制的能力。

   - 广域网（WLAN）——> 自治系统（AS）——> 局域网（LAN），都通过路由器相连接。

   - 两种最短路径算法：Bellman-Ford、Dijkstra's
   - 自治系统内寻路：RIP
   - 自治系统间寻路：BGP
   - 子网划分
   - 中继系统：路由器（router）

3. 传输层：在底下三层的基础上，我们已经可以实现主机间的通信，传输层实现的是不同进程间的通信。传输层向用户提供可靠的端到端的差错和流量控制，保证报文的正确传输。向高层屏蔽下层数据通信的细节，即向用户透明地传送报文。通信的端点是主机中的进程/端口。
   - TCP/UDP：transmission control protocal/user datagram protocal
   - Socket：用IP:Port表示一个套接字

4. 应用层：将应用程序的信息进行加工( 产物为“报文段” )，并传递给下一个层次( 传输层 )。将传输层传过来的信息进行加工( 产物还是“报文段” )，并传递给应用程序。
   - DNS、FTP、SMTP
   - HTTP：使用明文；无状态/记忆协议；
   - HTTPS

> 理解：
>
> Hosts通过hub相连成为一个LAN/Ethernet，LAN通过switch/bridge相连成为一个Big LAN/Ethernet/subnet，Big LAN通过router相连成为一个AS，AS通过router相连成为WLAN/Internet。
>
> AS间和AS内的寻址通过查询router上的routing table。在router中的ARP Table找到目的地MAC后，在LAN/Ethernet内的MAC寻址通过查询switch/bridge上的Filtering Database找到目的地MAC所在。
>
> 
>
> 物理层解决了电信号的传播；
>
> 数据链路层解决了电信号传播中可能出现的差错，以广播的方式确保了数据可以从一个MAC地址传到另一个MAC地址；到这里其实理论上所有的主机都可以进行通信了，但是如果全世界的电脑都以广播的方式来寻找目的MAC地址，就太不合理了；
>
> 我们设计网络层，使用地址（xxx.xxx.xxx.xxx/xx）来划分**子网**，在同一子网下的就使用**广播**的方式发送，否则转发到默认网关，再路由转发至目的地IP所在子网。
>
> 到这里我们已经实现世界范围内主机的通信，传输层实现了主机的不同进程（port）间的通信。
>
> 最后应用层在传输层的基础下，通过不同应用层协议把传输层传来的数据进行加工交给进程处理。



## 2. DNS查询过程

#### 域名的层级：map.google.com.root

1. 根域名：.root，对于所有的域名都一样
2. 顶级域名：.com/.net
3. 次级域名：.google，用户可以注册
4. 子域名：.map，次级域名派生的域名
5. 主机名：最左侧标签标识特定的服务器

#### 域名的查询过程：

1. 访问域名www.google.com.
2. 查询本地Hosts文件和DNS缓存，有则直接返回对应IP
3. 查询本地DNS服务器（TCP/IP参数中设置的首选DNS服务器），有则直接返回
4. 访问根域名服务器，查询顶级域名服务器的IP地址
5. 访问顶级域名服务器，查询次级域名服务器的IP地址
6. 访问次级域名服务器，直到查询到提供服务的主机的IP地址





## 3. TCP/UDP

一个TCP/UDP connection用一个五元组标识：(tcp/udp, local IP, local port, remote IP, remote port)

可靠的传输方式：只要不得到确认，就重新发送数据报，直到得到对方的确认为止。

#### TCP三次握手

1. 客户端向服务器发出同步请求：SYN=1，seq=x（客户端的初始序号）；

2. 服务器端收到报文，发出同步确认报文：SYN=1，ACK=1，ack=x+1（确认收到了对方序号为x的报文），seq=y（服务器端的初始序号）；

3. 客户端收到报文，给出确认：ACK=1，ack=y+1（确认收到了对方序号为y的报文），seq=x+1（客户端的序号）。

4. 发送完毕后，客户端进入 ESTABLISHED状态，当服务器端接收到这个包时，也进入ESTABLISHED状态，TCP 握手结束。

   >  为什么需要三次握手？
   >
   >  握手的目的：
   >
   >  - 防止已失效的SYN报文延迟一段时间后又传送到了服务端，假设此时双方的通信已经完成，如果只有两次握手，服务端单方面建立与客户端连接导致浪费。所以一定要跟客户端确认。
   >  - 需要通信双方对彼此的数据原点（Initial sequence number）得到确认，后面的通信控制都基于ISN。三次握手才能够让双方都确认收到彼此的初始序列号。
   >
   >  第三次握手可以携带数据，第一次握手不携带数据是为了防止SYN攻击。
   
   <img src="https://raw.githubusercontent.com/HIT-Alibaba/interview/master/img/tcp-connection-made-three-way-handshake.png" alt="three-way-handshake" style="zoom:70%;" />

#### TCP四次挥手

1. 客户端发出连接释放请求：FIN=1，seq=u；

2. 服务器端收到报文，发出确认报文：ACK=1，ack=u+1，seq=v；（服务器已收到请求，但是可能有没发完的数据）

3. 服务器端将最后的数据发送完后，发送连接释放报文：FIN=1，ACK=1，ack=u+1，seq=w；

4. 客户端收到报文，必须发出确认：ACK=1，ack=w+1，seq=u+1。

   > 挥手发起方TIME_WAIT等待2MSL的目的：
   >
   > - 保证最后一个ACK包能被服务端收到，因为服务端如果在LAST_ACK状态等待一段时间没收到客户端的ACK包，就会重传FIN-ACK包。2MSL恰好是客户端发出的ACK报文的MSL + 服务端重发的FIN报文的MSL。
   > - 防止已失效的报文段出现在下一次连接中。经过2MSL时间后，可以保证在本次连接中传输的报文段都在网络中消失。
   >
   > 服务器TIME_WAIT状态的连接过多带来的问题：
   >
   > - 对于web应用来说，服务端开启一个监听端口对外提供服务，TIME_WAIT很多对于服务端来说不会出现耗尽端口的情况；
   > - 因为每个连接都对应着一块内核缓冲区，如果不及时释放就会消耗大量的内核空间，造成浪费。
   >
   > - 解决方法：开启重用，允许将TIME-WAIT sockets重新用于新的TCP连接；开启TIME_WAIT下Socket的快速回收；修改系統默认的 TIMEOUT 时间。

   <img src="https://raw.githubusercontent.com/HIT-Alibaba/interview/master/img/tcp-connection-closed-four-way-handshake.png" alt="four-way-handshake" style="zoom:70%;" />



#### socket通信的系统调用

Server：

- 使用socket()函数创建一个socket，指明使用的传输层协议；
- 使用bind()函数将IP地址和端口号与socket绑定；
- 使用listen()函数进入监听状态，如果同时有多个请求，会产生一个请求队列在缓冲区中；
- 使用accept()函数接收客户端的连接请求，accept()会阻塞直到有新的请求到来，然后返回一个新的socketfd来标识并与客户端通信。这里的socketfd并没有分配一个新的端口。

Client：

- 使用socket()函数创建一个socket，返回一个socketfd；
- 使用connect()函数向server的socket发出建立连接请求；
- 使用socketfd来标识并于服务端通信。

<img src="C:\Users\ag\AppData\Roaming\Typora\typora-user-images\image-20200412222627578.png" alt="image-20200412222627578" style="zoom:40%;" />



#### TCP流量控制

流量控制针对的是发送方和接收方**速度不匹配**的问题。如果发送者发送数据过快，接收者来不及接收，那么就会有分组丢失。为了避免分组丢失，控制发送者的发送速度，使得接收者来得及接收，这就是流量控制。

流量控制由**滑动窗口协议**实现。滑动窗口协议既保证了流量控制，也实现了分组无差错、有序接收。

流量控制是由**接收者**控制的，通过窗口控制发送者的发送速度从而使接收者来得及接收，防止分组丢失。



#### TCP拥塞控制

拥塞控制是作用于**网络**的，它是防止过多的数据注入到网络中，避免出现网络负载过大的情况；

常用的方法就是：

1. **慢开始算法**：发送方维持一个**拥塞窗口**，拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方的滑动窗口**小于等于**该拥塞窗口以及接收方的滑动窗口。

   慢开始算法的思路就是，不要一开始就发送大量的数据，先探测一下网络的拥塞程度，也就是说由小到大逐渐增加拥塞窗口的大小。每经过一个传输轮次，拥塞窗口cwnd就加倍。

   > 为了防止cwnd增长过大引起网络拥塞，还需设置一个慢开始门限ssthresh变量。ssthresh的用法如下：
   >
   > 当cwnd<ssthresh时，使用慢开始算法。
   > 当cwnd>ssthresh时，改用拥塞避免算法。
   > 当cwnd=ssthresh时，慢开始与拥塞避免算法任意

2. **拥塞避免算法**：拥塞避免算法让拥塞窗口缓慢增长，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。

3. **快重传算法**：快重传要求接收方在收到一个失序的报文段后就**立即发出重复确认**（为的是使发送方及早知道有报文段没有到达对方，可提高网络吞吐量约20%）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。

   **快恢复算法**：快重传配合使用的还有快恢复算法。当发送方连续收到三个重复确认时，就执行“**乘法减小**”算法，把ssthresh门限减半（为了预防网络发生拥塞）。但是接下去并不执行慢开始算法，考虑到如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方现在认为网络可能没有出现拥塞。所以此时不执行慢开始算法，而是将cwnd设置为ssthresh减半后的值，然后**执行拥塞避免算法**，使cwnd缓慢增大。


![preview](https://pic4.zhimg.com/v2-3319d090787d8941cea25376e284679b_r.jpg)



#### UDP

1. UDP是一个非连接的协议，尽可能快地把来自应用程序的数据扔到网络上。UDP尽最大努力交付，即不保证可靠交付，因此主机不需要维持复杂的链接状态表，可以同时向多个客户机传输相同的消息。

2. UDP信息包的头部很短，只有8个字节，TCP有20个字节。

3. UDP支持一对一、一对多、多对一的通信模式；TCP只支持点对点。

4. UDP没有拥塞控制，流量控制，差错控制，不可靠。

5. UDP面向数据报（Datagram），UDP不会切分应用层传来的数据，加个Header就递给网络层传输；

   TCP面向数据流/报文段（Segment），TCP把应用层的数据看成是数据流，如果太大了就会对其进行切分，保证其小于等于1460（Ethernet MTU - IP header - TCP header）。

6. UDP一般应用在不要求质量要求速度的场景，语音、视频、直播等。



## 4. HTTP

1. HTTP是一个**基于TCP/IP**通信协议来传递数据的协议，传输的数据类型为HTML 文件、图片、查询结果等。

   HTTP允许传输任意类型的数据对象。传输的类型由Content-Type加以标记。

3. **无状态性**：每次连接只处理一个请求，不能保持会话连接，为了弥补这种不足，产生了两种记录HTTP状态的技术——Cookie、Session。

   - Cookie：由服务器生成，**发送并存储在浏览器**的一个**key-value对**，浏览器在下次请求同一服务器时会将该Cookie附上。
   - Session：由服务器生成，**存储在服务器端**的一种**数据结构**（一般是哈希表），前端仅需保存一个SessionId（可以保存在Cookie中），用来跟踪用户的状态。
   - Token：用户登录成功后服务器生成一个加密Token，前端每次请求附上这个Token给后端校验。适用于集群。

3. 因为使用**明文传输**，存在安全问题，由此产生HTTPS。

4. HTTP长连接：keep-alive，实际上指的是TCP长连接，我们平时用的都是长连接，因为一般请求一个网页时会包含多个HTTP的资源请求，所以使用长连接复用一个TCP连接。

5. 请求/响应报文的组成：请求行/状态行（方法、URI、HTTP版本）、首部、正文。

6. 报文首部的组成：Content-Type、Keep-Alive、Cookie等。

7. 状态码：

   - 1**：信息，服务器收到部分请求，需要请求者继续提出请求；
   - 2**：成功，操作被成功接收且处理；
   - 3**：请求的资源的URI发生变更，或是提供操作列表供请求者选择；
   - 4**：客户端错误，请求包含语法错误或无法完成请求；
   - 5**：服务器错误，服务器在处理请求的过程中发生错误。

8. GET/POST区别：

   - GET把参数包含在 URL 中，POST通过request body传递参数，POST方法更为安全
   - GET由长度限制，POST写在body中没有长度限制。
   - GET在浏览器回退时是无害的，而POST会再次提交请求。

9. HTTPS：在HTTP的基础上使用SSL（Secure Socket Layer）建立安全的通信线路。首先HTTP请求服务端生成数字证书（包含公钥）返回给客户端，客户端使用公钥加密一个随机数发送给服务端，服务端用私钥解密得到随机数，再用AES加密这个随机数，作为密钥互相加密解密内容来进行后续通信。

   > 对称加密：双方使用同一个密钥来加密解密内容进行通信。（DES/AES）
   >
   > 非对称加密：使用算法生成一对公钥私钥，一方通过公钥加密信息，一方通过私钥解密信息。（RSA）



#### HTTP/1.1和HTTP/2：

- 同一个HTTP/1.1虽然支持复用TCP连接，但是只能串行处理请求，后面的请求都会被阻塞；HTTP/2有多路复用机制，能够让多个请求同时共用同一个连接且互不影响，无需先入先出。
- 在HTTP/2中，客户端向某个域名的服务器请求页面的过程中，只会创建一条TCP连接，即使这页面可能包含上百个资源。而HTTP/1.1的客户端一般会创建6-8条TCP连接来并行请求这100多个资源。
- HTTP/2中服务端主动push客户端很可能需要的资源。
- HTTP/2中对Header进行了压缩，在同一连接上的多个请求其实Header差不多。